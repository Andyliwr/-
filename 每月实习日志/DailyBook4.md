#####东吴在线实习笔记（四）
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;到东吴来的第四个月了，这个月的还是比较轻松，处理一些angular项目的bug，空余时间我都在写自个的爬虫程序。
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;也不知道什么时候的想法，可能是uc浏览器的免费小说取消掉了这件事刺激到了我，所以就决心自己写一个小说的爬虫程序，从网上自个爬小说的数据。当时自己也在学node，这个想法出现没多久我就在github上建立了一个myapp的项目，其中就有一个项目--网络小说爬虫。设计这个爬虫过程其实是比较曲折的，前前后后得有33个提交，代码也由最初的demo变成了更加复杂的爬虫程序。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;程序的大体技术如下，使用node-schedule控制爬虫每隔一天执行一次，所有网站的配置未见在config.js里（你可以在里面新建一个网站源）。对于每隔网站源，使用superangent发请求去获取网页html源码，在使用cheerio分析html源码，解析出你想要的数据所在的标签-firstSign和secondSign，对于二级网页，使用eventproxy控制并发，当所有爬虫都返回，整理数据，并存入mongo。所以等后期程序完毕，你只需要在config里新增网页源就可以拿到你想要的数据，不过这应该还差很远，继续努力吧。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;总体上我对这个爬虫程序还是比较满意的，自动化运行，兼有日志系统，稳定的数据存储，唯一的缺陷就是没法通过手机看到爬到的数据，就是缺乏一个展示的东西。后期也会慢慢完善的。现在爬虫程序会在每天晚上6点开始爬数据，以后会慢慢加入起点，天下电子书的小说源。